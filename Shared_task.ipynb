{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeD_asz6-1uf",
        "outputId": "8a8928d9-5d09-46fe-dac9-1880a7c62b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r \"/content/drive/MyDrive/NLP - shared task/Codebase/reference/requirements.txt\""
      ],
      "metadata": {
        "id": "Uk7OJfbtJOJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tiQvlDhLJdH",
        "outputId": "e4f86994-21e8-4bea-ace6-0e872400ee41",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221124-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 15.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=ab3eb50a02e259534c08753b862e230179387bd4dba9bd331207d1a2dcf058f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221124 types-pytz-2022.6.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/NLP - shared task/Codebase/')"
      ],
      "metadata": {
        "id": "D73-iLtCJP0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/NLP - shared task/Dataset/ILDC_single.csv\")"
      ],
      "metadata": {
        "id": "A7Pw8bWJPrPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.tseries.frequencies import unique\n",
        "print(\"split types:\", unique(data.split))\n",
        "print(\"classes:\", unique(data.label))\n",
        "print(data.head())\n",
        "print(\"----------Sample Text-------------\")\n",
        "print(data.text[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG7HopZ4VpNW",
        "outputId": "595cc2e3-c45a-4b60-fe73-e6d4f2246f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split types: ['train' 'test' 'dev']\n",
            "classes: [1 0]\n",
            "                                                text  label  split  \\\n",
            "0   F. NARIMAN, J. Leave granted. In 2008, the Pu...      1  train   \n",
            "1   S. THAKUR, J. Leave granted. These appeals ar...      0  train   \n",
            "2   Markandey Katju, J. Leave granted. Heard lear...      1  train   \n",
            "3   ALTAMAS KABIR,J. Leave granted. The question ...      1  train   \n",
            "4   CIVIL APPEAL NO. 598 OF 2007 K. MATHUR, J. Th...      1  train   \n",
            "\n",
            "            name  \n",
            "0   2019_890.txt  \n",
            "1   2014_170.txt  \n",
            "2   2010_721.txt  \n",
            "3  2008_1460.txt  \n",
            "4   2008_188.txt  \n",
            "----------Sample Text-------------\n",
            " F. NARIMAN, J. Leave granted. In 2008, the Punjab State Water Supply Sewerage Board, Bhatinda issued numberice inviting tender for extension and augmentation of water supply, sewerage scheme, pumping station and sewerage treatment plant for various towns mentioned therein on a turnkey basis. On 25.9.2008, the appellant companypany, which is Signature Not Verified involved in civil electrical works in India, was awarded the said Digitally signed by NIDHI AHUJA Date 2019.03.11 173359 IST Reason tender after having been found to be the best suited for the task. On 16.1.2009, a formal companytract was entered into between the appellant and respondent No. 2. It may be mentioned that the numberice inviting tender formed part and parcel of the formal agreement. Contained in the numberice inviting tender is a detailed arbitration clause. In this matter, we are companycerned with clause 25 viii  which is set out as follows- viii. It shall be an essential term of this companytract that in order to avoid frivolous claims the party invoking arbitration shall specify the dispute based on facts and calculations stating the amount claimed under each claim and shall furnish a deposit-at-call for ten percent of the amount claimed, on a schedule bank in the name of the Arbitrator by his official designation who shall keep the amount in deposit till the announcement of the award. In the event of an award in favour of the claimant, the deposit shall be refunded to him in proportion to the amount awarded w.r.t the amount claimed and the balance, if any, shall be forfeited and paid to the other party. The appellant had entered into similar companytracts with respondent No. 2 which companytained the same arbitration clause. It had therefore addressed letters to respondent No. 2 with regard to appointment of arbitrator in those matters and sought for waiving the 10 deposit fee. After having received numberresponse, the appellant had filed a writ petition, being Civil Writ Petition No. 18917 of 2016, before the High Court of Punjab and Haryana. This writ petition was dismissed by a judgment dated 14.9.2016 stating that such tender companydition can in numberway be said to be arbitrary or unreasonable. On 8.3.2017, the appellant approached the High Court of Punjab and Haryana challenging the validity of this part of the arbitration clause by filing Civil Writ Petition No. 4882 of 2017. The High Court in the impugned judgment merely followed its earlier judgment and dismissed this writ petition as well. Learned companynsel appearing on behalf of the appellant has argued that the arbitration clause companytained in the tender companydition amounts to a companytract of adhesion, and since there is unfair bargaining strength between respondent No. 2 and the appellant, this clause ought to be struck down following the judgment in Central Inland Water Transport Corpn. v. Brojo Nath Ganguly,  1986  3 SCC 156. He has also argued that arbitration being an alternative dispute resolution process, a 10 deposit would amount to a clog on entering the aforesaid process. Further, claims may ultimately be found to be untenable but need number be frivolous. Also, frivolous claims can be companypensated by heavy companyts. Further, even in the event that the award is in favour of the claimant, what can be refunded to him is only in proportion to the amount awarded and the rest is to be forfeited. This would also be a further arbitrary and highhanded action on the part of respondent No. 2. Learned companynsel appearing on behalf of the respondents has argued that there is numberinfraction of Article 14 in the present case. It is clear that clause 25 viii  would apply to both the parties equally, and as this is so, the said sub-clause cannot be struck down as being discriminatory. Further, the principle companytained in Central Inland Water Transport Corpn.  supra  cannot possibly be applied to companymercial companytracts. Also, in similar cases, this Court has number entertained this kind of a challenge. Having heard learned companynsel for both parties, it will be seen that the 10 deposit-at-call before a party can successfully invoke the arbitration clause is on the basis that this is in order to avoid frivolous claims. Clause 25 xv  is also material and is set out hereinbelow xv. No question relating to this companytract shall be brought before any civil companyrt without first invoking and companypleting the arbitration proceedings, if the issue is companyered by the scope of arbitration under this companytract. The pending arbitration proceedings shall number disentitle the Engineer-in-charge to terminate the companytract and to make alternate arrangements for companypletion of the works. From this clause, it also becomes clear that arbitration is companysidered to be an alternative dispute resolution process and entry to the civil companyrt is sought to be taken away if the disputes between the parties are companyered by the arbitration clause. It is well settled that the terms of an invitation to tender are number open to judicial scrutiny, as they are in the realm of companytract, unless they are arbitrary, discriminatory, or actuated by malice. Thus, in Directorate of Education v. Educomp Datamatics Ltd.,  2004  4 SCC 19, this Court held It is well settled number that the companyrts can scrutinise the award of the companytracts by the Government or its agencies in exercise of their powers of judicial review to prevent arbitrariness or favouritism. However, there are inherent limitations in the exercise of the power of judicial review in such matters. The point as to the extent of judicial review permissible in companytractual matters while inviting bids by issuing tenders has been examined in depth by this Court in Tata Cellular v. Union of India  1994  6 SCC 651. After examining the entire case-law the following principles have been deduced The principles deducible from the above are The modern trend points to judicial restraint in administrative action. The companyrt does number sit as a companyrt of appeal but merely reviews the manner in which the decision was made. The companyrt does number have the expertise to companyrect the administrative decision. If a review of the administrative decision is permitted it will be substituting its own decision, without the necessary expertise which itself may be fallible. The terms of the invitation to tender cannot be open to judicial scrutiny because the invitation to tender is in the realm of companytract. Normally speaking, the decision to accept the tender or award the companytract is reached by process of negotiations through several tiers. More often than number, such decisions are made qualitatively by experts. The Government must have freedom of companytract. In other words, a fair play in the joints is a necessary companycomitant for an administrative body functioning in an administrative sphere or quasi-administrative sphere. However, the decision must number only be tested by the application of Wednesbury principle of reasonableness  including its other facts pointed out above  but must be free from arbitrariness number affected by bias or actuated by mala fides. Quashing decisions may impose heavy administrative burden on the administration and lead to increased and unbudgeted expenditure.  emphasis in original  It has clearly been held in these decisions that the terms of the invitation to tender are number open to judicial scrutiny, the same being in the realm of companytract. That the Government must have a free hand in setting the terms of the tender. It must have reasonable play in its joints as a necessary companycomitant for an administrative body in an administrative sphere. The companyrts would interfere with the administrative policy decision only if it is arbitrary, discriminatory, mala fide or actuated by bias. It is entitled to pragmatic adjustments which may be called for by the particular circumstances. The companyrts cannot strike down the terms of the tender prescribed by the Government because it feels that some other terms in the tender would have been fair, wiser or logical. The companyrts can interfere only if the policy decision is arbitrary, discriminatory or mala fide. To similar effect is the decision in Global Energy Ltd. v. Adani Exports Ltd.,  2005  4 SCC 435, where this Court held The principle is, therefore, well settled that the terms of the invitation to tender are number open to judicial scrutiny and the companyrts cannot whittle down the terms of the tender as they are in the realm of companytract unless they are wholly arbitrary, discriminatory or actuated by malice. This being the position of law, settled by a catena of decisions of this Court, it is rather surprising that the learned Single Judge passed an interim direction on the very first day of admission hearing of the writ petition and allowed the appellants to deposit the earnest money by furnishing a bank guarantee or a bankers cheque till three days after the actual date of opening of the tender. The order of the learned Single Judge being wholly illegal, was, therefore, rightly set aside by the Division Bench. As has companyrectly been argued by learned companynsel appearing on behalf of the respondents, this companyrts judgment in Central Inland Water Transport Corpn.  supra , which lays down that companytracts of adhesion, i.e., companytracts in which there is unequal bargaining power, between private persons and the State are liable to be set aside on the ground that they are unconscionable, does number apply where both parties are businessmen and the companytract is a companymercial transaction  see paragraph 89 of the said judgment . In this view of the matter, the argument of the appellant based on this judgment must fail. In S.K. Jain v. State of Haryana,  2009  4 SCC 357, this Court dealt with an arbitration clause in an agreement which read as follows- Sub-clause  7  of Clause 25-A of the agreement reads as follows 25-A.  7  It is also a term of this companytract agreement that where the party invoking arbitration is the companytractor, numberreference for arbitration shall be maintainable unless the companytractor furnishes to the satisfaction of the Executive Engineer in charge of the work, a security deposit of a sum determined according to details given below and the sum so deposited shall, on the termination of the arbitration proceedings be adjusted against the companyts, if any, awarded by the arbitrator against the claimant party and the balance remaining after such adjustment in the absence of any such companyts being awarded, the whole of the sum will be refunded to him within one month from the date of the award Amount of claim Rate of security deposit 1For claims below Rs 2 of amount . 10,000 claimed 2For claims of Rs 10,000 5 of amount . and above and below Rs claimed 1,00,000 and 3For claims of Rs 1,00,000 7 of amount . and above claimed. In upholding such a clause, this Court referred to the judgment in Central Inland Water Transport Corpn.  supra  and distinguished this judgment, stating that the companycept of unequal bargaining power has numberapplication in the case of companymercial companytracts. It then went on to hold- It has been submitted by learned companynsel for the appellant that there should be a cap in the quantum payable in terms of sub-clause  7  of Clause 25-A. This plea is clearly without substance. It is to be numbered that it is structured on the basis of the quantum involved. Higher the claim, the higher is the amount of fee chargeable. There is a logic in it. It is the balancing factor to prevent frivolous and inflated claims. If the appellants plea is accepted that there should be a cap in the figure, a claimant who is making higher claim stands on a better pedestal than one who makes a claim of a lesser amount. It will be numbericed that in this judgment there was numberplea that the aforesaid companydition companytained in an arbitration clause was violative of Article 14 of the Constitution of India as such clause is arbitrary. The only pleas taken were that the ratio of Central Inland Water Transport Corpn.  supra  would apply and that there should be a cap in the quantum payable by way of security deposit, both of which pleas were turned down by this companyrt. Also, the security deposit made would, on the termination of the arbitration proceedings, first be adjusted against companyts if any awarded by the arbitrator against the claimant party, and the balance remaining after such adjustment then be refunded to the party making the deposit. This clause is materially different from clause 25 viii , which, as we have seen, makes it clear that in all cases the deposit is to be 10 of the amount claimed and that refund can only be in proportion to the amount awarded with respect to the amount claimed, the balance being forfeited and paid to the other party, even though that other party may have lost the case. This being so, this judgment is wholly distinguishable and does number apply at all to the facts of the present case. In ABL International Ltd. v. Export Credit Guarantee Corpn. of India Ltd.,  2004  3 SCC 553, this Court has held that even within the companytractual sphere, the requirement of Article 14 to act fairly, justly and reasonably by persons who are state authorities or instrumentalities companytinues. Thus, this Court held It is clear from the above observations of this Court, once the State or an instrumentality of the State is a party of the companytract, it has an obligation in law to act fairly, justly and reasonably which is the requirement of Article 14 of the Constitution of India. Therefore, if by the impugned repudiation of the claim of the appellants the first respondent as an instrumentality of the State has acted in companytravention of the abovesaid requirement of Article 14, then we have numberhesitation in holding that a writ companyrt can issue suitable directions to set right the arbitrary actions of the first respondent xxx xxx xxx From the above discussion of ours, the following legal principles emerge as to the maintainability of a writ petition In an appropriate case, a writ petition as against a State or an instrumentality of a State arising out of a companytractual obligation is maintainable. xxx xxx xxx From the above, it is clear that when an instrumentality of the State acts companytrary to public good and public interest, unfairly, unjustly and unreasonably, in its companytractual, companystitutional or statutory obligations, it really acts companytrary to the companystitutional guarantee found in Article 14 of the Constitution Thus, it must be seen as to whether the aforesaid clause 25 viii  can be said to be arbitrary or discriminatory and violative of Article 14 of the Constitution of India. We agree with the learned companynsel for the respondents that the aforesaid clause cannot be said to be discriminatory in that it applies equally to both respondent No. 2 and the appellant. However, arbitrariness is a separate and distinct facet of Article 14. In A.L. Kalra v. The Project Equipment Corporation of India Limited, 1984 3 S.C.R. 646, this Court turned down a submission that arbitrariness is only a facet of discrimination. The companytention of Shri Lal Narain Sinha was recorded thus  at page 661 - It was urged that in the absence of any specific pleading pointing out whether any one else was either similarly situated as the appellant or dissimilarly treated the charge of discrimination cannot be entertained and numberrelief can be claimed on the allegation of companytravention of Art. 14 or Art. 16 of the Constitution. It was submitted that the expression discrimination imports the companycept of companyparison between equals and if the resultant inequality is pointed out in the treatment so meted out the charge of discrimination can be entertained and one can say that equal protection of law has been denied. Expanding the submission, it was urged that the use of the expression equality in Art. 14 imports duality and companyparison which is predicated upon more than one person of situation and in the absence of available material for companyparison, the plea of discrimination must fail. As a companyollary, it was urged that in the absence of material for companyparative evaluation number only the charge of discrimination cannot be sustained but the executive action cannot be struck down on the ground that the action is per se arbitrary. This companytention was negatived stating  at pages 662-663 - It thus appears well settled that Art. 14 strikes at arbitrariness in executive administrative action because any action that is arbitrary must necessarily involve the negation of equality. One need number companyfine the denial of equality to a companyparative evaluation between two persons to arrive at a companyclusion of discriminatory treatment. An action per se arbitrary itself denies equal of protection by law. The Constitution Bench pertinently observed in Ajay Hasias case 1981 2 S.C.R. 79 and put the matter beyond companytroversy when it said wherever therefore, there is arbitrariness in State action whether it be of the legislature or of the executive or of an authority under Article 12, Article 14 immediately springs into action and strikes down such State action. This view was further elaborated and affirmed in D.S. Nakara v. Union of India 1983 1 SCC 305. In Maneka Gandhi v. Union of India 1978 2 S.C.R. 621 it was observed that Art. 14 strikes at arbitrariness in State action and ensure fairness and equality of treatment. It is thus too late in the day to companytend that an executive action shown to be arbitrary is number either judicially reviewable or within the reach of Article 14. We have thus to see whether clause 25 viii  can be said to be arbitrary and violative of Article 14 of the Constitution of India. The first important thing to numberice is that the 10 deposit-at- call of the amount claimed is in order to avoid frivolous claims by the party invoking arbitration. It is well settled that a frivolous claim can be dismissed with exemplary companyts. Thus, in Dnyandeo Sabaji Naik v. Pradnya Prakash Khadekar,  2017  5 SCC 496, this Court held Courts across the legal systemthis Court number being an exceptionare choked with litigation. Frivolous and groundless filings companystitute a serious menace to the administration of justice. They companysume time and clog the infrastructure. Productive resources which should be deployed in the handling of genuine causes are dissipated in attending to cases filed only to benefit from delay, by prolonging dead issues and pursuing worthless causes. No litigant can have a vested interest in delay. Unfortunately, as the present case exemplifies, the process of dispensing justice is misused by the unscrupulous to the detriment of the legitimate. The present case is an illustration of how a simple issue has occupied the time of the companyrts and of how successive applications have been filed to prolong the inevitable. The person in whose favour the balance of justice lies has in the process been left in the lurch by repeated attempts to revive a stale issue. This tendency can be curbed only if companyrts across the system adopt an institutional approach which penalises such behaviour. Liberal access to justice does number mean access to chaos and indiscipline. A strong message must be companyveyed that companyrts of justice will number be allowed to be disrupted by litigative strategies designed to profit from the delays of the law. Unless remedial action is taken by all companyrts here and number our society will breed a legal culture based on evasion instead of abidance. It is the duty of every companyrt to firmly deal with such situations. The imposition of exemplary companyts is a necessary instrument which has to be deployed to weed out, as well as to prevent the filing of frivolous cases. It is only then that the companyrts can set apart time to resolve genuine causes and answer the companycerns of those who are in need of justice. Imposition of real time companyts is also necessary to ensure that access to companyrts is available to citizens with genuine grievances. Otherwise, the doors would be shut to legitimate causes simply by the weight of undeserving cases which flood the system. Such a situation cannot be allowed to companye to pass. Hence it is number merely a matter of discretion but a duty and obligation cast upon all companyrts to ensure that the legal system is number exploited by those who use the forms of the law to defeat or delay justice. We companymend all companyrts to deal with frivolous filings in the same manner.  Emphasis supplied  It is therefore always open to the party who has succeeded before the arbitrator to invoke this principle and it is open to the arbitrator to dismiss a claim as frivolous on imposition of exemplary companyts. We may also numberice this Courts judgment in General Motors  I   P  Ltd. v. Ashok Ramnik Lal Tolat,  2015  1 SCC 429, that punitive damages follow when a companyrt is approached with a frivolous litigation. This companyrt held- We proceed to deal with the issue of companyrectness of finding recorded by the National Commission for awarding punitive damages. Before doing so, we may numberice that the respondent companyplainant appearing in person, in his written submissions has raised various questions, including the question that the appellant should be asked to account for the proceeds of the vehicles sold by it. Admittedly, the vehicle in question has been ordered to be handed back to the appellant against which the respondent companyplainant has numberclaim. Thus, the plea raised is without any merit. The other issue raised for further punitive damages of Rs. 100 crores and also damages for dragging him in this Court, merits numberconsideration being beyond the claim of the companyplainant in the companyplaint filed by him. Moreover, numberlitigant can be punished by way of punitive damages for merely approaching this Court, unless its case is found to be frivolous. The important principle established by this case is that unless it is first found that the litigation that has been embarked upon is frivolous, exemplary companyts or punitive damages do number follow. Clearly, therefore, a deposit-at-call of 10 of the amount claimed, which can amount to large sums of money, is obviously without any direct nexus to the filing of frivolous claims, as it applies to all claims  frivolous or otherwise  made at the very threshold. A 10 deposit has to be made before any determination that a claim made by the party invoking arbitration is frivolous. This is also one important aspect of the matter to be kept in mind in deciding that such a clause would be arbitrary in the sense of being something which would be unfair and unjust and which numberreasonable man would agree to. Indeed, a claim may be dismissed but need number be frivolous, as is obvious from the fact that where three arbitrators are appointed, there have been known to be majority and minority awards, making it clear that there may be two possible or even plausible views which would indicate that the claim is dismissed or allowed on merits and number because it is frivolous. Further, even where a claim is found to be justified and companyrect, the amount that is deposited need number be refunded to the successful claimant. Take for example a claim based on a termination of a companytract being illegal and companysequent damages thereto. If the claim succeeds and the termination is set aside as being illegal and a damages claim of one crore is finally granted by the learned arbitrator at only ten lakhs, only one tenth of the deposit made will be liable to be returned to the successful party. The party who has lost in the arbitration proceedings will be entitled to forfeit nine tenths of the deposit made despite the fact that the aforesaid party has an award against it. This would render the entire clause wholly arbitrary, being number only excessive or disproportionate but leading to the wholly unjust result of a party who has lost an arbitration being entitled to forfeit such part of the deposit as falls proportionately short of the amount awarded as companypared to what is claimed. Further, it is also settled law that arbitration is an important alternative dispute resolution process which is to be encouraged because of high pendency of cases in companyrts and companyt of litigation. Any requirement as to deposit would certainly amount to a clog on this process. Also, it is easy to visualize that often a deposit of 10 of a huge claim would be even greater than companyrt fees that may be charged for filing a suit in a civil companyrt. This Court in State of JK v. Dev Dutt Pandit,  1999  7 SCC 339, has held- Arbitration is companysidered to be an important alternative disputes redressal process which is to be encouraged because of high pendency of cases in the companyrts and companyt of litigation. Arbitration has to be looked up to with all earnestness so that the litigant public has faith in the speedy process of resolving their disputes by this process. What happened in the present case is certainly a paradoxical situation which should be avoided. Total companytract is for Rs. 12,23,500. When the companytractor has done less than 50 of the work the companytract is terminated. He has been paid Rs 5,71,900. In a Section 20 petition he makes a claim of Rs. 39,47,000 and before the arbitrator the claim is inflated to Rs. 63,61,000. He gets away with Rs. 20,08,000 with interest at the rate of 10 per annum and penal interest at the rate of 18 per annum. Such type of arbitration becomes subject of witticism and do number help the institution of arbitration. Rather it brings a bad name to the arbitration process as a whole. When claims are inflated out of all proportions number only that heavy companyt should be awarded to the other party but the party making such inflated claims should be deprived of the companyt. We, therefore, set aside the award of companyt of Rs. 7500 given in favour of the companytractor and against the State of Jammu and Kashmir.  Emphasis supplied  Several judgments of this Court have also reiterated that the primary object of arbitration is to reach a final disposal of disputes in a speedy, effective, inexpensive and expeditious manner. Thus, in Centrotrade Minerals Metal Inc. v. Hindustan Copper Ltd.,  2017  2 SCC 228, this companyrt held In Union of India v. U.P. State Bridge Corpn. Ltd.  2015  2 SCC 52 this Court accepted the view O.P. Malhotra on the Law and Practice of Arbitration and Conciliation  3rd Edn. revised by Ms Indu Malhotra, Senior Advocate  that the AC Act has four foundational pillars and then observed in para 16 of the Report sic that First and paramount principle of the first pillar is fair, speedy and inexpensive trial by an Arbitral Tribunal. Unnecessary delay or expense would frustrate the very purpose of arbitration. Interestingly, the second principle which is recognised in the Act is the party autonomy in the choice of procedure. This means that if a particular procedure is prescribed in the arbitration agreement which the parties have agreed to, that has to be generally resorted to.  Emphasis in original  Similarly, in Union of India v. Varindera Constructions Ltd.,  2018  7 SCC 794, this Court held- The primary object of the arbitration is to reach a final disposition in a speedy, effective, inexpensive and expeditious manner. In order to regulate the law regarding arbitration, legislature came up with legislation which is known as Arbitration and Conciliation Act, 1996. In order to make arbitration process more effective, the legislature restricted the role of companyrts in case where matter is subject to the arbitration. Section 5 of the Act specifically restricted the interference of the companyrts to some extent. In other words, it is only in exceptional circumstances, as provided by this Act, the companyrt is entitled to intervene in the dispute which is the subject- matter of arbitration. Such intervention may be before, at or after the arbitration proceeding, as the case may be.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "Ax1d8bl_XOqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import statistics\n",
        "import math\n",
        "import numpy as np\n",
        "from typing import List\n",
        "import spacy\n",
        "import torch\n",
        "import random\n",
        "from collections import Counter\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import openai"
      ],
      "metadata": {
        "id": "HVrdtLVOWjtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "aQOK89k9WD5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = data[data.split == 'train'].text.to_list()\n",
        "train_y = data[data.split == 'train'].label.to_list()\n",
        "dev_X = data[data.split == 'dev'].text.to_list()\n",
        "dev_y = data[data.split == 'dev'].label.to_list()\n",
        "test_X = data[data.split == 'test'].text.to_list()\n",
        "test_y = data[data.split == 'test'].label.to_list()"
      ],
      "metadata": {
        "id": "kQg2yTiDxRX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset visualization"
      ],
      "metadata": {
        "id": "Og-3ZBX_Ljp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "total = len(data)\n",
        "train_per =  round(len(train_X) / total, 2)\n",
        "dev_per = round(len(dev_X) / total, 2)\n",
        "test_per = round(len(test_X) / total, 2)\n",
        "\n",
        "\n",
        "y = np.array([train_per, dev_per, test_per])\n",
        "labels = [f'Training: {train_per * 100}%', f'Validation: {dev_per * 100}%', f'Testing: {test_per * 100}%']\n",
        "plt.pie(y, labels=labels, shadow=True, explode=[0.2,0,0])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "QnSKytZfLg1a",
        "outputId": "28b21402-7a04-4260-a7e1-6580dd23e98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "distribution = Counter(data.label)\n",
        "\n",
        "plt.pie([distribution[0], distribution[1]], labels=[f'Denied {round((distribution[0] / len(data)) * 100, 2)}%', 'Accepted'], shadow=True, explode=[0.2,0])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "lfoEhERmNCD2",
        "outputId": "bbfbaa79-239e-4b3c-aef6-adfe00a03ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "arr = []\n",
        "max_len = 0\n",
        "avg_len = 0\n",
        "min_len = float('inf')\n",
        "for t in data.text:\n",
        "  max_len = max(max_len, len(t))\n",
        "  min_len = min(min_len, len(t))\n",
        "  avg_len += len(t)\n",
        "\n",
        "avg_len = avg_len / len(data)\n",
        "\n",
        "# print(math.log(max_len), math.log(min_len), math.log(avg_len))\n",
        "\n",
        "plt.bar([\"min text len\", 'avg text len', 'max text len'], [math.log(min_len), math.log(avg_len), math.log(max_len)], color ='maroon',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Text lengths\")\n",
        "plt.ylabel(\"No. of words\")\n",
        "plt.title(\"Text length distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xQplfJMvPHXc",
        "outputId": "77556f15-d999-4af8-895f-06ddc31f36db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive bayes classifier"
      ],
      "metadata": {
        "id": "JnOQw4B7ZHzU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpQXOdGtdGvW",
        "outputId": "684fcc7c-1946-4748-b1c4-ca95995810aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "vec = CountVectorizer(stop_words='english')\n",
        "x = vec.fit_transform(train_X).toarray()\n",
        "dev_tr_X = vec.transform(dev_X).toarray()\n",
        "\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x, train_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNMa2MNOgIxr",
        "outputId": "dbb0c411-b1b6-421e-bab9-df44e477d0ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5895372233400402"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(dev_tr_X, dev_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression"
      ],
      "metadata": {
        "id": "gTMVnDf6ZU-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this will be step 2 towards improvement\n",
        "# we can report various results with different hyper parameters\n",
        "import tqdm.notebook as tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from gensim.models import KeyedVectors\n",
        "import torch\n",
        "from torch.nn.functional import normalize\n",
        "\n",
        "class LogisticRegressionClassifier(torch.nn.Module):\n",
        "    def __init__(self, k:int, input_dim:int, hidden_dim:int, output_dim:int):\n",
        "        super().__init__()\n",
        " \n",
        "        self.countvectorizer = None\n",
        "        self.tfidfvectorizer = None\n",
        "        self.count_wm = None\n",
        "        self.tfidf_wm = None\n",
        "        self.count_tokens = None\n",
        "        self.tfidf_tokens = None\n",
        "        self.k = k\n",
        "        self.input_dim =  input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # https://osf.io/qvg8s/wiki/home/ : Legal domain word2vec\n",
        "        self.legal_word2vec = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin\", binary=True, unicode_errors='ignore') \n",
        "        print(\"legal_word2vec dimension : {}\".format(len(self.legal_word2vec[\"legal\"])))\n",
        "\n",
        "        self.layer1 = torch.nn.Linear(self.input_dim, self.hidden_dim)\n",
        "        self.classifier = torch.nn.Linear(self.hidden_dim, self.output_dim)\n",
        "\n",
        "        self.initialize_weights()\n",
        "\n",
        "        self.dev_f1_history = []\n",
        "                                          \n",
        "    def fit(self, texts, labels):\n",
        "        self.countvectorizer = CountVectorizer(analyzer= 'word', stop_words= 'english')\n",
        "        self.tfidfvectorizer = TfidfVectorizer(analyzer= 'word', stop_words= 'english')\n",
        "        \n",
        "        self.count_wm = self.countvectorizer.fit_transform(texts)\n",
        "        self.tfidf_wm = self.tfidfvectorizer.fit_transform(texts)\n",
        "        \n",
        "        self.count_tokens = self.countvectorizer.get_feature_names_out()\n",
        "        self.tfidf_tokens = self.tfidfvectorizer.get_feature_names_out()\n",
        "    \n",
        "    def extract_features(self, texts):\n",
        "        reserved_k = 100\n",
        "        k = self.k\n",
        "\n",
        "        wm = self.tfidfvectorizer.transform(texts)\n",
        "        train_featured = []\n",
        "        for i,row in tqdm.tqdm(enumerate(wm)):\n",
        "          feature = []\n",
        "          topk_ind = row.indices[row.data.argsort()[-reserved_k:]]\n",
        "          topk_words = logistic_regression_classifier.tfidf_tokens[topk_ind]\n",
        "\n",
        "          found = 0    \n",
        "          j = len(topk_words) - 1\n",
        "          while(k>found):\n",
        "            word = topk_words[j]\n",
        "            while (word not in logistic_regression_classifier.legal_word2vec):\n",
        "              #print(\" [-] {} is not in word2vec\".format(word))\n",
        "              j=j-1\n",
        "              word = topk_words[j]\n",
        "            vec = logistic_regression_classifier.legal_word2vec[word]\n",
        "            feature.extend(vec)\n",
        "            found += 1    \n",
        "            j=j-1\n",
        "          train_featured.append(feature)\n",
        "        train_featured_torch = torch.FloatTensor(train_featured)\n",
        "        return normalize(train_featured_torch, p=1.0, dim = 1)\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        stdv = 1. / math.sqrt(self.layer1.weight.size(1))\n",
        "        self.layer1.weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "        stdv = 1. / math.sqrt(self.classifier.weight.size(1))\n",
        "        self.classifier.weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, features: torch.Tensor) -> torch.Tensor:\n",
        "        l1 = self.layer1(features)\n",
        "        output = self.classifier(l1)\n",
        "        return torch.sigmoid(output)\n",
        "\n",
        "    def predict(self, dev_features: torch.Tensor):\n",
        "        preds = []\n",
        "        #preds = torch.argmax(self(dev_features))\n",
        "        preds = (self(dev_features).squeeze() > 0.5).float()\n",
        "        return preds\n",
        "\n",
        "    def training_loop(\n",
        "        self, \n",
        "        num_epochs,\n",
        "        train_features,\n",
        "        train_labels,\n",
        "        dev_features,\n",
        "        dev_labels,\n",
        "        optimizer\n",
        "    ):\n",
        "        print(\"Training...\")\n",
        "        #loss_func = torch.nn.NLLLoss()\n",
        "        loss_func = torch.nn.BCELoss() # EDITED(TS)\n",
        "        batches = list(zip(train_features, train_labels))\n",
        "        random.shuffle(batches)\n",
        "\n",
        "        for i in range(num_epochs):\n",
        "            losses = []\n",
        "            for features, labels in tqdm.tqdm(batches):\n",
        "                # Empty the dynamic computation graph\n",
        "                optimizer.zero_grad()\n",
        "                preds = self(features).squeeze()\n",
        "                loss = loss_func(preds, labels)\n",
        "                # Backpropogate the loss through our model\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                losses.append(loss.item())\n",
        "            \n",
        "            print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
        "            # Estimate the f1 score for the development set\n",
        "            print(\"Evaluating dev...\")\n",
        "            preds = self.predict(dev_features)\n",
        "            dev_f1 = f1_score(preds, dev_labels)\n",
        "            print(f\"Dev F1 {dev_f1}\")\n",
        "            self.dev_f1_history.append(dev_f1)\n",
        "            \n",
        "        # Return the trained model\n",
        "        return self"
      ],
      "metadata": {
        "id": "tgv_x-984Xth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logistic_regression_classifier = LogisticRegressionClassifier(k=20, input_dim=4000, hidden_dim=400, output_dim=1)\n",
        "logistic_regression_classifier.fit(train_X, train_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE4HrZWzQc42",
        "outputId": "8d366a97-9564-4d3c-8b7a-23a652128fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.utils_any2vec:duplicate word 'pagn' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'prs' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'caf' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'sd' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'ros' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'fiance' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'ral' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'ol' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'attach' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word '' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'pan' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'urea' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'sf' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word '' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'expos' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'sol' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'employ' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'resum' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'ert' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'fiance' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'maym' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'e' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'ne' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'employs' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'tre' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'g' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'len' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 's' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'dor' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'pea' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'cap' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'darn' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n",
            "WARNING:gensim.models.utils_any2vec:duplicate word 'fr' in /content/drive/MyDrive/NLP - shared task/Dataset/legalrawtextreplacewithnnp.bin, ignoring all but first\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "legal_word2vec dimension : 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X_features = logistic_regression_classifier.extract_features(train_X)\n",
        "dev_X_features   = logistic_regression_classifier.extract_features(dev_X)\n",
        "test_X_features  = logistic_regression_classifier.extract_features(test_X)\n",
        "train_y_torch = torch.FloatTensor(train_y)\n",
        "dev_y_torch = torch.FloatTensor(dev_y)\n",
        "test_y_torch = torch.FloatTensor(test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "50c4470bdf77410db2a908c4e12116a8",
            "0fc17bc749c44ddbb2214cbfd6b74060",
            "bfd9c726b3764c38b053e1547f41d86b",
            "9c28921c0d10409c91563c8fcd080dfc",
            "bdc7e6e834c14a2aacc7702f6dca0839",
            "a5010a7c56614d6496b36cbc0bcf8643",
            "b619aba1545141d38e86295430a665b5",
            "e155b73ae3d44081bc7833b36eb31544",
            "1f37ffec65d644f88666289999797bf5",
            "7028d889e1d241b4a9acdb56e7cc3792",
            "b184ca650ed84d70a9880e9aafdca7bf",
            "577bccf828d14ac6a51bec49f7c0e914",
            "45aee1472eb346059374b9e00cd7564c",
            "b884cfc3dfd64d0e9f0bc465aeb6eb4a",
            "7a3a13e7f25f4c3db81ce8f4c8e1d14b",
            "ccadf8152b994e0581b24a06f199403c",
            "84e11067e95d445dbefa4e197ea3bc1b",
            "bb6588986a0a4dbea578f2034aee2db1",
            "f2c523257ea64c41ad0c22f0f8d9f78d",
            "a471c1954dac4253be1e43fb4dd3f763",
            "c324f0b363af45bc97a5f1ce38ef8a55",
            "a29ffe0b3d44489db24fd5f4d54184c4",
            "a1869f850a7b4ddc9ac065264a459390",
            "fc8157b44f9a4408a1914cb2dfc5fc13",
            "e87d9f5914f44e748689cd13ba11c1a9",
            "d5abe44f7a764d5c935f50750eeaa8e9",
            "39019d73f17e4e5fade1a4b024b06920",
            "ad4f929e4bc94f0ea39f25c1bdf5d39a",
            "03ad3025ebcf408d821a85d95581d574",
            "0f59f114786b4e2884073d875c933493",
            "f68d163652b242c2b062653c29e9ff31",
            "0a280eca34c048eaaab56dc1ecc44ce5",
            "33487fa2b775486599349e339418454c"
          ]
        },
        "id": "rVpAczngCmTK",
        "outputId": "1827eba1-df31-40fa-8f0f-e19334996d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50c4470bdf77410db2a908c4e12116a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "577bccf828d14ac6a51bec49f7c0e914"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1869f850a7b4ddc9ac065264a459390"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim = torch.optim.Adam(logistic_regression_classifier.parameters(), lr=0.0004)\n",
        "model = logistic_regression_classifier.training_loop(10, train_X_features, train_y_torch, dev_X_features, dev_y_torch, optim)\n",
        "torch.save(model.state_dict(), \"trained_lr_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875,
          "referenced_widgets": [
            "59d6462315274548a4e061e92f53884d",
            "3257d2493bb2498aac7f5bf85f3f2c59",
            "6d51a97caa2440fc86b5be29a87f9d0f",
            "2b372b9e58ee4a40b110c7b8d33e0804",
            "b13835cc79714bfcabfc37dbcc6dd0e8",
            "6e9cdba8a3454ab895b9e675849a4773",
            "e33e27193a2e438c8626c40991fda356",
            "463037d908654dc486e782aa3a2ee00c",
            "66f05c118c744840bbd5c1b67d28b1f2",
            "0eebd4387b66437ea32b4ed427057acb",
            "2d223a6c3d284f98bab0e7cf58e5af16",
            "612514b6ded041719a6b0843080c3669",
            "3ff846d07fdc4641a9cf481698c4748d",
            "4a08038150d84238a9a5462ddc8a19e9",
            "4afd4c35040e475589006c88e10cb4b3",
            "321459fcde0441398b17c0bb7f1548d4",
            "d6226877a50347629be87ac5fb4055e1",
            "c944a9e445164526842f4d4c9c8fa798",
            "c4f0490deb034180b9f5863b3773918f",
            "84d4d88f350047a09740bca9a0a32338",
            "16314f98edea4b0eaa0c2cfffd13322b",
            "95090e74341c41f2acc9dc7c33ea2711",
            "17c069ff2549439099f4bda2d2852b2c",
            "86466b416be04f88b7a7ed2a06647c71",
            "e67be2f4337a4fc1b60fb24d852acee5",
            "cb5a7a74dc964b1fb25818968799c68f",
            "5f44e20214a144a0a82ed0bb959e6548",
            "4c1068bb7590447c89771fc58c441d38",
            "c434343449f548aab259ac35a280f3f6",
            "9af50ef359ea42c89465c6d78f62b456",
            "6fc1d24a45c1446cb609dd1365633924",
            "49ce566fea0c4fdd86a49380cf2a7bfb",
            "035878b98b4543dfab740f7307769acb",
            "fa26d7b4093d493da1df66b8cd883dff",
            "843151fc0d414cf0b18d05beb6d540de",
            "7de1b123d03345289e69e7fdc1d6bf32",
            "e9c0fe51774543e0a08f71c26466219c",
            "58094eb26ee346faab425f6d6838f9f0",
            "4c4cedd8957249ab84b4a23a8c7567ac",
            "25944ed1cfa04630a8ec99f8b03622d7",
            "245089e9ad814648853fccacd7cddfcc",
            "de806e512e4f4edc9fc8cfc106618259",
            "6ab23c8d8a8f4d8fa91ca1fa55564d27",
            "0a1ead7d0efb4fc8910f29a187d4a1df",
            "c9504e94ef374d5b81f4aff4ecfe2670",
            "e90e6ac35265488ea40ad9728add1d5a",
            "ade13415bfe14686b6124bfce6b62ed0",
            "e999326666db47ae9af97fb16ad77ef4",
            "6adeb122ff314e56acff2ea08b62c009",
            "d65dec517f414ac993565d2d744a7109",
            "ad8c8a0072d24968b0e7a39276d87759",
            "50f6d12e8ba543b4acd2ec3d05208b64",
            "8421ef692ffc4759925f56c1ddaa5eae",
            "bf5f681467454eb59e1bb03bcb01743f",
            "0a8077199aec45f8835db99c0915ed52",
            "3fb315b490c449969b6deef10cdb98a6",
            "75235865ecf941c7b762b18b6b245fd6",
            "b72d507dc7fc4ccab176410bf33571e0",
            "7b7838a5347c430f8b04c5ca6c68f4b5",
            "647652a16c93465d86bbc4351540b2a4",
            "72a7824bb4f6464bb7ed2998aae49b87",
            "51f78113a82e4469b29c5ac80d55471b",
            "248d3a1021ce4c9383ed647262f56f3b",
            "cf2bde0fae60499688e2a6a2028dd0d1",
            "9eac539bfaa04c17b5edcbb53ba15326",
            "824d093d4b8743dfa07f6e6cfbfa95e3",
            "af0d1caac7c543958ecea521d85588f3",
            "17343e8e814e47f1ad42028c00111b63",
            "0a173732dee34d70a72f1fd026111642",
            "600142115b30400ab78582acef2ad503",
            "bbe42afa76104f2ca391ea93a345deb1",
            "4b4ab67819014a3ea02733997e6a653f",
            "ec6e4f2c83e945078890fa7e1732a6f9",
            "f743595072fc45e1aabb33f6c3e70f28",
            "b7529a9bb88b4969b4563c689af18e9d",
            "bbca8a32b0df4239b83495a3c46d138c",
            "676e5c00129047a9844f54df6572c646",
            "267351ee35144e04b46651a0fdf973bc",
            "566fc7c4f5fb44f5a0b26bced1f484e3",
            "a906ef706ec8418db7ceaedd25cecce1",
            "d06baeb20b7a478f8d77835a940b23d1",
            "c31ada2f9afd4cf69663a3e594be76f5",
            "e548b349297b4a5298c455a1cb493b6e",
            "224defb8cb2a4f97a74450405168ec0f",
            "06df34539ab849b6ac8dfafb2b2a3923",
            "bb43afae142c4a139fe7a13faf662549",
            "409a8128cc6e48a0b2e239d6e706b5e9",
            "48e4dfea9db84a89841057247c96a15c",
            "07baf4d7a7234aeebc9ad620d296f077",
            "72532f7a7aaf4d988a298a8f67ec283f",
            "026971fe2d3246c1a278464305ef28b3",
            "6e57d1bc8ba54669982527282fdab604",
            "f056d4ffef384147b838549e5bfe6c3c",
            "a26557f056e945ec9c9d5e7c6ebf34ec",
            "30e37033ce3c4042a8c4fb55561681f8",
            "f82bd60e54fc45bfa475108977a02c74",
            "33ba7ecf919048bfa8f77dac41dd81f6",
            "2e8d3880effa4069be2403dd602ac0a7",
            "72fc64f4ded44024bcd4f53084e206c2",
            "d0a69a513e9c4f719458f4ecaea6dae0",
            "d6823bb9b4194097812bdedaf39b8334",
            "2cc30ba1e6614d87bfaf095e16c115dc",
            "934f39f71fed4556a185a83d850466df",
            "bb2c7a911c2f4682a78e17e5cdf8fb39",
            "8f1bd13ff07f4281b1d4b93489ef3e77",
            "246fddb0f61d4376b47995b5532bf561",
            "fa116d560f7747d486ba911f9f8b2156",
            "2872174a06d34622955a56046e9a5933",
            "1aadffea303d423a955e903c2f3b463a",
            "e2aacf9db8c949dfadbf982107e816be"
          ]
        },
        "id": "O89dNLEl66e5",
        "outputId": "8f2464e5-8564-4cde-ea50-b50cad4745b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59d6462315274548a4e061e92f53884d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss: 0.1589700795369683\n",
            "Evaluating dev...\n",
            "Dev F1 0.4128553770086526\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "612514b6ded041719a6b0843080c3669"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss: 0.09388533501619963\n",
            "Evaluating dev...\n",
            "Dev F1 0.4282238442822384\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17c069ff2549439099f4bda2d2852b2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, loss: 0.09325801244365789\n",
            "Evaluating dev...\n",
            "Dev F1 0.4418604651162791\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa26d7b4093d493da1df66b8cd883dff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3, loss: 0.07389413647536835\n",
            "Evaluating dev...\n",
            "Dev F1 0.46490218642117376\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9504e94ef374d5b81f4aff4ecfe2670"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4, loss: 0.07348209404582146\n",
            "Evaluating dev...\n",
            "Dev F1 0.45833333333333337\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fb315b490c449969b6deef10cdb98a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5, loss: 0.08294779254471887\n",
            "Evaluating dev...\n",
            "Dev F1 0.5158562367864693\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af0d1caac7c543958ecea521d85588f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 6, loss: 0.07451107210032765\n",
            "Evaluating dev...\n",
            "Dev F1 0.47005649717514125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "267351ee35144e04b46651a0fdf973bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 7, loss: 0.08439674897892029\n",
            "Evaluating dev...\n",
            "Dev F1 0.4721906923950057\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07baf4d7a7234aeebc9ad620d296f077"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 8, loss: 0.06841611007558417\n",
            "Evaluating dev...\n",
            "Dev F1 0.47032474804031354\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5082 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0a69a513e9c4f719458f4ecaea6dae0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 9, loss: 0.06992356797825287\n",
            "Evaluating dev...\n",
            "Dev F1 0.5042735042735043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = logistic_regression_classifier\n",
        "model.load_state_dict(torch.load(\"trained_lr_model_0.52_0.53.pth\"))\n",
        "\n",
        "preds = model.predict(train_X_features)\n",
        "train_f1  = f1_score(preds, train_y_torch)\n",
        "train_acc = accuracy(preds, train_y_torch)\n",
        "print(f\"Train F1  {train_f1}\")\n",
        "print(f\"Train Acc {train_acc}\")\n",
        "\n",
        "preds = model.predict(dev_X_features)\n",
        "dev_f1  = f1_score(preds, dev_y_torch)\n",
        "dev_acc = accuracy(preds, dev_y_torch)\n",
        "print(f\"Dev F1  {dev_f1}\")\n",
        "print(f\"Dev Acc {dev_acc}\")\n",
        "\n",
        "preds = model.predict(test_X_features)\n",
        "test_f1  = f1_score(preds, test_y_torch)\n",
        "test_acc = accuracy(preds, test_y_torch)\n",
        "print(f\"Test F1  {test_f1}\")\n",
        "print(f\"Test Acc {test_acc}\")\n",
        "#torch.save(model.state_dict(), \"trained_lr_model_0.52_0.53.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5iPGIPg7u-D",
        "outputId": "46e76c02-3152-48cf-8130-4ecd20cc3823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5082\n",
            "5082\n",
            "Train F1  0.8826355525051476\n",
            "Train Acc 0.8990554899645808\n",
            "994\n",
            "994\n",
            "Dev F1  0.528263103802672\n",
            "Dev Acc 0.5382293762575453\n",
            "1517\n",
            "1517\n",
            "Test F1  0.512549537648613\n",
            "Test Acc 0.5135135135135135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unlike LSTM or Transformer which identifies the association between nearby words and extracts their meaning, it is difficult to do so in Linear regression. So, in order to extract the main words and their meanings and use them for inference, the following two pieces of information were extracted in my algorithm.\n",
        "\n",
        "Firstly, in order find the important main keyword, TF-IDF is used here. Rather than simply counting the occurrence of a specific word to determine its importance, it enables to extract the keyword of the sentence by judging whether it appears frequently in the target sentence while not appearing frequently in other documents. In this implementation, 20 keywords were extracted by using TF-IDF.\n",
        "\n",
        "Secondly, in the next step, we find the meaning of the keywords extracted above. The meaning of these keywords will represent the meaning of the entire document, and then approval/rejection can be determined based on it. \n",
        "\n",
        "In general, word2vec or glove express semantic information of the words in the form of vectors. However, the documents and words we deal with are legal terms. Since general word2vec may not have legal meaning, I used the word2vec of legal words from \"SigmaLaw - Large Legal Text Corpus and Word Embeddings\". (https://osf.io/qvg8s/)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GhB80SWiZqjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi-LSTM\n"
      ],
      "metadata": {
        "id": "v-NaPnZkHXFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Tokenizer with Padding"
      ],
      "metadata": {
        "id": "0vLmdnYc5-Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "\n",
        "    def __init__(self, pad_symbol = \"<PAD>\"):\n",
        "\n",
        "        self.pad_symbol = pad_symbol\n",
        "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "    \n",
        "\n",
        "    def __call__(self, batch):\n",
        "\n",
        "        batch = self.tokenize(batch)\n",
        "        batch = self.pad(batch)\n",
        "\n",
        "        return batch\n",
        "\n",
        "\n",
        "    def tokenize(self, sentences):\n",
        "\n",
        "        tokenized_sent = []\n",
        "        \n",
        "        for sent in sentences:\n",
        "            tokenizer = self.nlp(sent)\n",
        "            cleaned_sent = [token.lemma_.lower() for token in tokenizer if \\\n",
        "                (token.is_stop is False) and (token.is_punct is False) \\\n",
        "                and (token.like_url is False) and (token.like_email is False) \\\n",
        "                and (token.is_alpha is True)]\n",
        "            \n",
        "            cleaned_sent.insert(0, '<SOS>')\n",
        "            cleaned_sent.append('<EOS>')\n",
        "            tokenized_sent.append(cleaned_sent)\n",
        "            \n",
        "        return tokenized_sent\n",
        "\n",
        "\n",
        "    def pad(self, batch):\n",
        "\n",
        "        max_len = 0\n",
        "\n",
        "        for i in batch:\n",
        "            if len(i) > max_len:\n",
        "                max_len = len(i)\n",
        "        \n",
        "        for j in batch:\n",
        "            if max_len > len(j):\n",
        "                j.extend(['<PAD>'] * (max_len-len(j)))\n",
        "            else:\n",
        "                continue\n",
        "        \n",
        "        # Check the sentences length are the same\n",
        "        \n",
        "        len_check = 0\n",
        "        \n",
        "        for k in batch:\n",
        "            len_check += len(k)\n",
        "        \n",
        "        if len_check/len(batch) != len(batch[0]):\n",
        "            print('Not All lengths are the same')\n",
        "       \n",
        "        return batch"
      ],
      "metadata": {
        "id": "Q7TZlqvm6Bus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the vocabulary of the dataset\n",
        "\n",
        "SPECIAL_TOKENS = ['<UNK>', '<PAD>', '<SOS>', '<EOS>']\n",
        "\n",
        "all_data = train_X + dev_X + test_X\n",
        "my_tokenizer = Tokenizer()\n",
        "\n",
        "tokenized_data = my_tokenizer.tokenize(all_data)\n",
        "vocab = sorted(set([w for ws in tokenized_data + [SPECIAL_TOKENS] for w in ws]))\n",
        "\n",
        "with open('vocab.txt', 'w') as vf:\n",
        "    vf.write('\\n'.join(vocab))"
      ],
      "metadata": {
        "id": "cQ4xCDptSdm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "RuqxA2GA6KJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_path = '/content/drive/MyDrive/NLP - shared task/glove.twitter.27B.50d.txt'\n",
        "vocab_path = \"/content/drive/MyDrive/NLP - shared task/vocab.txt\""
      ],
      "metadata": {
        "id": "xZxQD_VH6Fl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a custom Embedding Layer"
      ],
      "metadata": {
        "id": "9ylCyRU06piH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting word vectors from GloVe"
      ],
      "metadata": {
        "id": "4F6O_fQc6qr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pretrained_embeddings(embeddings_path, vocab_path):\n",
        "\n",
        "    word2i = {}\n",
        "    vectors = [] \n",
        "    \n",
        "    with open(vocab_path, encoding='utf8') as vf:\n",
        "        vocab = set([w.strip() for w in vf.readlines()]) \n",
        "    \n",
        "    print(f\"Reading embeddings from {embeddings_path}...\")\n",
        "    with open(embeddings_path, \"r\") as f:\n",
        "        i = 0\n",
        "        for line in f:\n",
        "            word, *weights = line.rstrip().split(\" \")\n",
        "\n",
        "            if word in vocab:\n",
        "                word2i[word] = i\n",
        "                i += 1\n",
        "                i_embeddings = [float(val) for val in line.split(' ')[1:]]\n",
        "                vectors.append(torch.FloatTensor(i_embeddings))\n",
        "\n",
        "    return word2i, torch.stack(vectors)"
      ],
      "metadata": {
        "id": "8tkQcMZB6pLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get GloVe Out of Vocabulary (oov) words\n"
      ],
      "metadata": {
        "id": "HzAIl2UR6wst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_oovs(vocab_path, word2i):\n",
        "\n",
        "    with open(vocab_path, encoding='utf8') as vf:\n",
        "        vocab = set([w.strip() for w in vf.readlines()])\n",
        "    \n",
        "    glove_and_vocab = set(word2i.keys())\n",
        "    vocab_and_not_glove = vocab - glove_and_vocab\n",
        "    \n",
        "    return list(vocab_and_not_glove)"
      ],
      "metadata": {
        "id": "rqirW2hb6wMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update the embeddings with oov words"
      ],
      "metadata": {
        "id": "aWmeqfsT62zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def intialize_new_embedding_weights(num_embeddings, dim):\n",
        "\n",
        "    w = torch.empty(num_embeddings, dim)\n",
        "    \n",
        "    return torch.nn.init.xavier_normal_(w)\n",
        "\n",
        "\n",
        "def update_embeddings(glove_word2i, glove_embeddings, oovs):\n",
        "\n",
        "    start_idx = len(glove_word2i)\n",
        "    \n",
        "    for i in oovs:\n",
        "        glove_word2i[i] = start_idx\n",
        "        start_idx += 1\n",
        "\n",
        "    new_embeddings = intialize_new_embedding_weights(len(oovs), len(glove_embeddings[0]))\n",
        "\n",
        "    return glove_word2i, torch.cat((glove_embeddings, new_embeddings), dim=0)"
      ],
      "metadata": {
        "id": "AQD93ahj62o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from irony import *\n",
        "\n",
        "def make_batches(sequences, batch_size):\n",
        "\n",
        "    batches = []\n",
        "    \n",
        "    for i in range(0, len(sequences), batch_size):\n",
        "        batches.append(sequences[i:i+batch_size])\n",
        "        \n",
        "    return batches\n",
        "\n",
        "\n",
        "glove_word2i, glove_embeddings = read_pretrained_embeddings(\n",
        "    embeddings_path,\n",
        "    vocab_path\n",
        ")\n",
        "\n",
        "# Find the out-of-vocabularies\n",
        "oovs = get_oovs(vocab_path, glove_word2i)\n",
        "\n",
        "# Add the oovs from training data to the word2i encoding, and as new rows\n",
        "# to the embeddings matrix\n",
        "word2i, embeddings = update_embeddings(glove_word2i, glove_embeddings, oovs)"
      ],
      "metadata": {
        "id": "C7KFSZ1xTSFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding words to integers"
      ],
      "metadata": {
        "id": "lR5wqqOT7Ins"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use these functions to encode the batches before call the train loop.\n",
        "\n",
        "def encode_sentences(batch, word2i):\n",
        "\n",
        "    UNK_IDX = word2i[\"<UNK>\"]\n",
        "    tensors = []\n",
        "    for sent in batch:\n",
        "        tensors.append(torch.LongTensor([word2i.get(w, UNK_IDX) for w in sent]))\n",
        "        \n",
        "    return torch.stack(tensors)\n",
        "\n",
        "\n",
        "def encode_labels(labels):\n",
        "\n",
        "    return torch.LongTensor([int(l) for l in labels])"
      ],
      "metadata": {
        "id": "RLw0pLbt62jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling\n"
      ],
      "metadata": {
        "id": "YEGkuvQG7Lwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class JudgementPredictor(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, embeddings_tensor, pad_idx, output_size, dropout_val = 0.3):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.pad_idx = pad_idx\n",
        "        self.dropout_val = dropout_val\n",
        "        self.output_size = output_size\n",
        "        self.embeddings = torch.nn.Embedding.from_pretrained(embeddings_tensor, freeze=True)\n",
        "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_val, inplace=False)\n",
        "        self.lstm = torch.nn.LSTM(\n",
        "            self.input_dim,\n",
        "            self.hidden_dim,\n",
        "            num_layers=2,\n",
        "            dropout=dropout_val,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "        self.classifier = torch.nn.Linear(hidden_dim*2, self.output_size)\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
        "    \n",
        "\n",
        "    def encode_text(self, symbols):\n",
        "\n",
        "        embedded = self.embeddings(symbols)\n",
        "        embedded = self.dropout_layer(embedded)\n",
        "        lens = (symbols != self.pad_idx).sum(dim=1).to(\"cpu\")\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(\n",
        "            embedded, lens, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        packed_outs, (H, C) = self.lstm(packed)\n",
        "        encoded, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
        "            packed_outs,\n",
        "            batch_first=True,\n",
        "            padding_value=self.pad_idx,\n",
        "            total_length=None,\n",
        "        )\n",
        "\n",
        "        encoded, (H, C) = self.lstm(embedded)\n",
        "\n",
        "        last_enc_out_idxs = lens - 1\n",
        "        last_enc_out_idxs = last_enc_out_idxs.view([encoded.size(0)] + [1, 1])\n",
        "        last_enc_out_idxs = last_enc_out_idxs.expand(\n",
        "            [-1, -1, encoded.size(-1)]\n",
        "        )\n",
        "        last_hidden = torch.gather(encoded, 1, last_enc_out_idxs)\n",
        "\n",
        "        return last_hidden\n",
        "    \n",
        "\n",
        "    def forward(self, symbols):\n",
        "      \n",
        "        encoded_sents = self.encode_text(symbols)\n",
        "        output = self.classifier(encoded_sents)\n",
        "\n",
        "        return self.log_softmax(output)"
      ],
      "metadata": {
        "id": "Gha7GegA7LnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "u45mGtu57PnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from regressor import *\n",
        "from itertools import chain\n",
        "\n",
        "def predict(model, dev_sequences):\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    for seq in dev_sequences:\n",
        "\n",
        "        # pass the input to model\n",
        "        softmax_output = model.forward(seq)\n",
        "        \n",
        "        # pickup the argmax at each tensor\n",
        "        seq_argmax = torch.argmax(torch.exp(softmax_output), dim=2)\n",
        "        seq_argmax_list = seq_argmax.squeeze(1).tolist()\n",
        "        preds.append(seq_argmax_list)\n",
        "\n",
        "    return np.fromiter(chain.from_iterable(preds), dtype='int').tolist()"
      ],
      "metadata": {
        "id": "-0hgPs037LlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "Nj66-ae27TDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from util import avg_f1_score, f1_score, accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def training_loop(\n",
        "    num_epochs,\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    dev_features,\n",
        "    dev_labels,\n",
        "    optimizer,\n",
        "    model\n",
        "):\n",
        "    print(\"Training...\")\n",
        "    loss_func = torch.nn.NLLLoss()\n",
        "    batches = list(zip(train_features, train_labels))\n",
        "    random.shuffle(batches)\n",
        "    \n",
        "    total_losses = [] \n",
        "    total_f1 = [] \n",
        "    total_avg_f1 = []\n",
        "    total_acc = [] \n",
        "    \n",
        "    for i in range(num_epochs):\n",
        "        losses = []\n",
        "        for features, labels in tqdm(batches):\n",
        "            # Empty the dynamic computation graph\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(features).squeeze(1)\n",
        "            loss = loss_func(preds, labels)\n",
        "            # Backpropogate the loss through our model\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.item())\n",
        "        \n",
        "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
        "        print(\"Evaluating dev...\")\n",
        "        predicted = predict(model, dev_features)\n",
        "        dev_f1 = f1_score(predicted, dev_labels, label2i['1'])\n",
        "        dev_avg_f1 = avg_f1_score(predicted, dev_labels, list(label2i.values()))\n",
        "        dev_acc = accuracy(predicted, dev_labels)\n",
        "\n",
        "        print(f\"Dev F1 {dev_f1}\")\n",
        "        print(f\"Avg Dev F1 {dev_avg_f1}\")\n",
        "        print(f\"Dev Accuracy {dev_acc}\")\n",
        "        \n",
        "        total_losses.append(sum(losses)/len(losses))\n",
        "        total_f1.append(dev_f1) \n",
        "        total_avg_f1.append(dev_avg_f1)\n",
        "        total_acc.append(dev_acc) \n",
        "    \n",
        "    print(f\"---------- Summary ----------\") \n",
        "    print(f\"min losss: {min(total_losses)}\")\n",
        "    print(f\"Max f1: {max(total_f1)}\") \n",
        "    print(f\"Max avg f1: {max(total_avg_f1)}\") \n",
        "    print(f\"Max accuracy: {max(total_acc)}\") \n",
        "    \n",
        "    plt.plot(total_losses)\n",
        "    plt.title('losses')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(total_f1 ,'r', label='F1')\n",
        "    plt.plot(total_avg_f1, 'b', label='Avg F1')\n",
        "    plt.title('F1 Scores')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    plt.plot(total_acc)\n",
        "    plt.title('Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "aRTbC7ls7Lh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initailize the model.\n",
        "\n",
        "model = JudgementPredictor(\n",
        "    input_dim = 50,\n",
        "    hidden_dim = 25,\n",
        "    embeddings_tensor = embeddings,\n",
        "    pad_idx = word2i['<PAD>'],\n",
        "    output_size = 2,\n",
        "    dropout_val = 0)\n",
        "\n",
        "batch_size = 16\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "encode_batch_tokenized_X_train_16 = []\n",
        "for batch in make_batches(train_X, batch_size):\n",
        "    encode_batch_tokenized_X_train_16.append(encode_sentences(tokenizer(batch), word2i))\n",
        "\n",
        "encode_batch_tokenized_X_dev_16 = []\n",
        "for batch in make_batches(dev_X, batch_size):\n",
        "    encode_batch_tokenized_X_dev_16.append(encode_sentences(tokenizer(batch), word2i))\n",
        "    \n",
        "encode_batch_y_train_16 = []\n",
        "for batch in make_batches(train_y, batch_size):\n",
        "    encode_batch_y_train_16.append(encode_labels(batch))\n",
        "    \n",
        "encode_y_dev = list(map(lambda x: int(x), dev_y))\n",
        "\n",
        "# Model hyperparameter setting\n",
        "num_epochs = 10\n",
        "LR=0.01\n",
        "# optimizer = torch.optim.SGD(model.parameters(), LR)\n",
        "# optimizer = torch.optim.RMSprop(model.parameters(), LR)\n",
        "optimizer = torch.optim.Adam(model.parameters(), LR)\n",
        "\n",
        "model = training_loop(\n",
        "    num_epochs,\n",
        "    encode_batch_tokenized_X_train_16,\n",
        "    encode_batch_y_train_16,\n",
        "    encode_batch_tokenized_X_dev_16,\n",
        "    encode_y_dev,\n",
        "    optimizer,\n",
        "    model\n",
        ")"
      ],
      "metadata": {
        "id": "vYVuvTqV7LYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep learning model with BERT"
      ],
      "metadata": {
        "id": "bM0er7iOZeYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another set of results with different hyper parameters"
      ],
      "metadata": {
        "id": "aBsGPCCBZ4eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "E3T-xviBRSlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJpUQA3tIZyo",
        "outputId": "927ab5a1-33fc-4d21-e811-72a6bdfc97ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "\n",
        "s_words_dict = defaultdict(None)\n",
        "\n",
        "for w in stopwords.words('english'):\n",
        "  s_words_dict[w] = 1\n",
        "\n",
        "\n",
        "def pre_process(texts):\n",
        "  mod_texts = []\n",
        "  for inp in texts:\n",
        "    text_tokens = word_tokenize(inp)\n",
        "    tokens_without_sw = []\n",
        "    for word in text_tokens:\n",
        "      if not s_words_dict.get(word):\n",
        "        tokens_without_sw.append(word)\n",
        "    mod_text = \" \".join(tokens_without_sw)\n",
        "    mod_texts.append(mod_text)\n",
        "  return mod_texts\n",
        "\n",
        "def truncate(texts):\n",
        "  tr_texts = []\n",
        "  for text in texts:\n",
        "    arr = text.split(\" \")\n",
        "    tr_arr = arr[len(arr) - 510: ]\n",
        "    tr_texts.append(\" \".join(tr_arr))\n",
        "  \n",
        "  return tr_texts\n",
        "\n",
        "train_input = truncate(pre_process(train_X))\n",
        "dev_input = truncate(pre_process(dev_X))\n",
        "test_input = truncate(pre_process(test_X))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U tensorflow\n",
        "# !pip install -U tensorflow-text\n",
        "import tensorflow_text as text\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "zfkEiKlnwqxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "SfZIhezbiSkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_ds(inps, labels):\n",
        "  tuple_ds = []\n",
        "  for i in range(len(inps)):\n",
        "    tuple_ds.append((inps[i], labels[i]))\n",
        "  return tuple_ds\n",
        "\n",
        "val_ds = convert_to_ds(dev_input, dev_y)"
      ],
      "metadata": {
        "id": "gwi14D6kq6-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose a BERT model to fine-tune\n",
        "\n",
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n",
        "\n",
        "map_name_to_handle = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/google/electra_small/2',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/google/electra_base/2',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
        "}\n",
        "\n",
        "map_model_to_preprocess = {\n",
        "    'bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_en_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'bert_multi_cased_L-12_H-768_A-12':\n",
        "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
        "    'albert_en_base':\n",
        "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
        "    'electra_small':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'electra_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_pubmed':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'experts_wiki_books':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "    'talking-heads_base':\n",
        "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "}\n",
        "\n",
        "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
        "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
        "\n",
        "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
        "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "1aMLaQEMm6sX",
        "outputId": "bb6436e2-a890-467f-afb7-5b0dd85857b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "T310The_iW71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqKuViJyionw",
        "outputId": "e77776e2-67b1-49d6-e6f8-4fd2340694fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_word_ids', 'input_type_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)\n",
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQjnn3VLisUW",
        "outputId": "06bd96ff-1a4b-4830-8754-017a3e805c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.7626287   0.99280983 -0.18611883  0.36673853  0.15233721  0.6550445\n",
            "  0.9681154  -0.9486271   0.00216147 -0.98777324  0.06842694 -0.9763059 ]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-0.289463    0.34321296  0.33231434 ...  0.2130085   0.7102072\n",
            "  -0.05771152]\n",
            " [-0.28742045  0.3198105  -0.23018534 ...  0.5845504  -0.2132971\n",
            "   0.72692066]\n",
            " [-0.6615697   0.6887678  -0.87433004 ...  0.10877264 -0.26173142\n",
            "   0.4785532 ]\n",
            " ...\n",
            " [-0.22561082 -0.28925622 -0.07064454 ...  0.47566032  0.8327713\n",
            "   0.40025327]\n",
            " [-0.29824215 -0.27473125 -0.0545053  ...  0.48849735  1.0955358\n",
            "   0.18163429]\n",
            " [-0.44378236  0.00930765  0.07223701 ...  0.17290132  1.1833243\n",
            "   0.0789801 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "XSQZFOohi7a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(tf.sigmoid(bert_raw_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p_uq8ZOi-fq",
        "outputId": "3b37fce2-4c84-4d0a-8dc2-419c06c58c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.633355]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(classifier_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "rbvwKzLXjAsr",
        "outputId": "6f5681bc-b257-4c14-d87b-5c89b7c4a0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.BinaryAccuracy()"
      ],
      "metadata": {
        "id": "cCsVRxtmjE3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model variations"
      ],
      "metadata": {
        "id": "2xwb1axRxNdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model version 1"
      ],
      "metadata": {
        "id": "ScZtZ-BCyjls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "init_lr = 3e-5"
      ],
      "metadata": {
        "id": "m3AZITPTjHyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer='adam',\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "QT16l23rjIo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training model with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_input, y=train_y, epochs=epochs, validation_data=(dev_input, dev_y))"
      ],
      "metadata": {
        "id": "Ze66fPL3jIL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f4a720-33b8-45bb-f11b-32233f44140f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/5\n",
            "159/159 [==============================] - 1431s 9s/step - loss: 0.7039 - binary_accuracy: 0.6122 - val_loss: 0.7965 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "159/159 [==============================] - 1404s 9s/step - loss: 0.6978 - binary_accuracy: 0.6141 - val_loss: 0.7256 - val_binary_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "159/159 [==============================] - 1405s 9s/step - loss: 0.6944 - binary_accuracy: 0.6120 - val_loss: 0.7058 - val_binary_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "159/159 [==============================] - 1397s 9s/step - loss: 0.6974 - binary_accuracy: 0.6143 - val_loss: 0.7260 - val_binary_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "159/159 [==============================] - 1408s 9s/step - loss: 0.6944 - binary_accuracy: 0.6129 - val_loss: 0.7174 - val_binary_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model version 2"
      ],
      "metadata": {
        "id": "2yxuLU6Syffk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate(texts):\n",
        "  tr_texts = []\n",
        "  for text in texts:\n",
        "    arr = text.split(\" \")\n",
        "    tr_arr = arr[len(arr) - 200: ]\n",
        "    tr_texts.append(\" \".join(tr_arr))\n",
        "  \n",
        "  return tr_texts\n",
        "\n",
        "train_input_v2 = truncate(pre_process(train_X))\n",
        "dev_input_v2 = truncate(pre_process(dev_X))\n",
        "test_input_v2 = truncate(pre_process(test_X))"
      ],
      "metadata": {
        "id": "Zl60BEAQyl-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "lr = 5e-5"
      ],
      "metadata": {
        "id": "V0KuMDP7xI1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer='adam',\n",
        "                         loss=loss,\n",
        "                         metrics=metrics)"
      ],
      "metadata": {
        "id": "dorh9r-oxVAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training model v2 with {tfhub_handle_encoder}')\n",
        "history = classifier_model.fit(x=train_input_v2, y=train_y, epochs=epochs, validation_data=(dev_input_v2, dev_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mh1SQmCxXrd",
        "outputId": "b70f4d7a-c999-4d96-df8a-8f8a5596eef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model v2 with https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Epoch 1/2\n",
            "159/159 [==============================] - 1442s 9s/step - loss: 0.7295 - binary_accuracy: 0.6043 - val_loss: 0.7232 - val_binary_accuracy: 0.5000\n",
            "Epoch 2/2\n",
            "159/159 [==============================] - 1416s 9s/step - loss: 0.6959 - binary_accuracy: 0.6124 - val_loss: 0.7006 - val_binary_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summarization with GPT-3"
      ],
      "metadata": {
        "id": "Z2Rg1IOW2mjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_test_X_1024 = []\n",
        "\n",
        "for i in range(len(test_X)):\n",
        "    a = re.sub('[^a-zA-Z]',' ',test_X[i])\n",
        "    b = ' '.join(a.split()).lower()\n",
        "    c = ' '.join(w for w in b.split() if len(w)>2)\n",
        "    d = ' '.join(c.split()[:1024])\n",
        "    cleaned_test_X_1024.append(d)"
      ],
      "metadata": {
        "id": "sp7OD9HL2rBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'It is a secret'\n",
        "openai.api_key = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "p28gOcWT3mNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "summary_1024 = []\n",
        "\n",
        "for i in range(len(cleaned_test_X_1024)):\n",
        "    response = openai.Completion.create(\n",
        "      model=\"text-davinci-002\",\n",
        "      prompt=f\"Summary the court judgement statement in two sentences.\\n\\nStatement: {cleaned_test_X_1024[i]}\\nSummary:\",\n",
        "      temperature=0,\n",
        "      max_tokens=60,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0.5,\n",
        "      presence_penalty=0\n",
        ")\n",
        "    summary_1024.append(response['choices'][0]['text'])\n",
        "    print(summary_1024)"
      ],
      "metadata": {
        "id": "gxK00pzX4DNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_1024_cleaned = []\n",
        "\n",
        "for i in range(len(summary_1024)):\n",
        "    summary_1024_cleaned.append(''.join(summary_1024[i][2:]))"
      ],
      "metadata": {
        "id": "rXWiWP9a4DK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_y_1024 = test_y[:369].copy()\n",
        "label = {0:'Rejected', 1:'Accepted'}\n",
        "result_1024 = [label[item] for item in test_y_1024]"
      ],
      "metadata": {
        "id": "IV9cE9qFUIfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_1024 = pd.DataFrame({'Sentence No.':test_X_name[:369], 'Reasoning':summary_1024_cleaned, 'Result':result_1024})\n",
        "name_1024.to_csv('GPT-3_summary of statements with result.csv', index=False)"
      ],
      "metadata": {
        "id": "tPfwAh9a4DID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_1024"
      ],
      "metadata": {
        "id": "0T0_jsco4WMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}